{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pytz  # Make sure to import pytz for timezone handling\n",
    "import seaborn as sns\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addtional setting session\n",
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the list of S&P 500 companies and their sectors\n",
    "def get_sp500_companies():\n",
    "    # Fetch the S&P 500 company symbols and sectors from a reliable source (e.g., Wikipedia)\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    tables = pd.read_html(url)\n",
    "    \n",
    "    # Extract the relevant table containing the company symbols and sectors\n",
    "    sp500_df = tables[0]\n",
    "    \n",
    "    # Return the DataFrame containing S&P 500 companies and sectors\n",
    "    return sp500_df[['Symbol', 'GICS Sector', 'GICS Sub-Industry']]\n",
    "\n",
    "\n",
    "# Function to create a dictionary of sectors and sub-sectors\n",
    "def create_sector_subsector_dict(df):\n",
    "    sector_subsector_dict = {}\n",
    "    for index, row in df.iterrows():\n",
    "        sector = row['GICS Sector']\n",
    "        subsector = row['GICS Sub-Industry']\n",
    "        if sector not in sector_subsector_dict:\n",
    "            sector_subsector_dict[sector] = [subsector]\n",
    "        else:\n",
    "            sector_subsector_dict[sector].append(subsector)\n",
    "    return sector_subsector_dict\n",
    "\n",
    "# Function to filter the S&P 500 companies by sector\n",
    "def company_sector_list(df, sector):\n",
    "    return df[df['GICS Sector'] == sector]['Symbol'].tolist()\n",
    "\n",
    "def company_sub_sector_list(df, sub_sector):\n",
    "    return df[df['GICS Sub-Industry'] == sub_sector]['Symbol'].tolist()\n",
    "\n",
    "\n",
    "# Get the list of S&P 500 companies and their sectors\n",
    "sp500_df  = get_sp500_companies()\n",
    "\n",
    "sp500_companies_sectors = sp500_df ['GICS Sector'].value_counts().index\n",
    "sp500_companies_sub_sectors = sp500_df ['GICS Sub-Industry'].value_counts().index\n",
    "\n",
    "sector_subsector_dict = create_sector_subsector_dict(sp500_df)\n",
    "\n",
    "\n",
    "# Function to create a DataFrame from the sector_subsector_dict\n",
    "def create_sector_dataframe():\n",
    "    # Create a list to store dictionacompany_sector_listries representing each row of data\n",
    "    data = []\n",
    "    \n",
    "    # Filter the DataFrame to get stocks in the specified sector\n",
    "    for sector in sp500_companies_sectors:\n",
    "        sector_stocks_list = company_sector_list(sp500_df, sector)\n",
    "\n",
    "        # Iterate over the stocks in the sector and create a dictionary for each\n",
    "        for i, ticker in enumerate(sector_stocks_list, start=1):\n",
    "            # Create a dictionary for the current stock in the sector\n",
    "            row_data = {'Sector': sector, 'Ticker': ticker}\n",
    "            # Append the dictionary to the list\n",
    "            data.append(row_data)\n",
    "    \n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "sector_subsector_dict = create_sector_subsector_dict(sp500_df)\n",
    "\n",
    "\n",
    "sector_ticker_df = create_sector_dataframe()\n",
    "energy_sector_ticker_list = sector_ticker_df[sector_ticker_df['Sector'] == 'Energy']['Ticker'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APA',\n",
       " 'BKR',\n",
       " 'CVX',\n",
       " 'COP',\n",
       " 'CTRA',\n",
       " 'DVN',\n",
       " 'FANG',\n",
       " 'EOG',\n",
       " 'EQT',\n",
       " 'XOM',\n",
       " 'HAL',\n",
       " 'HES',\n",
       " 'KMI',\n",
       " 'MRO',\n",
       " 'MPC',\n",
       " 'OXY',\n",
       " 'OKE',\n",
       " 'PSX',\n",
       " 'SLB',\n",
       " 'TRGP',\n",
       " 'VLO',\n",
       " 'WMB']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_sector_ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ask the user to input stock tickers separated by a comma\n",
    "# tickers_input = input(\"Enter stock tickers separated by commas:\")\n",
    "\n",
    "# # Split the input string into a list of tickers\n",
    "# tickers = tickers_input.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable dynamic query\n",
    "\n",
    "# input_security_dim = input()\n",
    "# input_security_func = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters section\n",
    "\n",
    "alpha_vantage_api_key = 'YI2V50P8VRQ3HFKM' # FREE TIER API rate limit is 25 requests per day\n",
    "alpha_vantage_function = {\n",
    "    'core':[\n",
    "        'TIME_SERIES_INTRADA'\n",
    "        ,'TIME_SERIES_DAILY' # this is daily time series quote\n",
    "        ,'TIME_SERIES_DAILY_ADJUSTED' # this is daily time series adjusted by split/dividend-adjusted\n",
    "        ,'GLOBAL_QUOTE'\n",
    "    ]\n",
    "    ,'fundmental':[\n",
    "    'INCOME_STATEMENT'\n",
    "    ,'BALANCE_SHEET' # this is daily time series quote\n",
    "    ,'CASH_FLOW' # this is daily time series adjusted by split/dividend-adjusted\n",
    "    ,'EARNINGS'\n",
    "    ,'EARNINGS_CALENDAR'\n",
    "]\n",
    "}\n",
    "\n",
    "# Define the ticker symbols as a list; eg. TSM,MSFT,AMZN\n",
    "# ticker_symbols = input(\"Enter stock tickers separated by commas:\") \n",
    "# ticker_symbols = ticker_symbols.split(',')\n",
    "ticker_symbols = [\n",
    "    'TSM'\n",
    "    ,'BABA'\n",
    "    ,'SYK'\n",
    "]\n",
    "\n",
    "# Time intelligent parameters\n",
    "window_days = 90\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=window_days)\n",
    "earning_calendar = [\n",
    "    3  # this will return next 1 qtr forecast earning; nowadays the earning calendar only shows the next 1 qtr forecast earning\n",
    "    ,6  # this will return next 2 qtr forecast earning\n",
    "    ,12  # this will return next 4 qtr forecast earning\n",
    "]\n",
    "\n",
    "\n",
    "ticker_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily quote section\n",
    "for symbol in ticker_symbols:\n",
    "\n",
    "    # Daily quote section\n",
    "    # replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={alpha_vantage_api_key}'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if key == 'Time Series (Daily)':\n",
    "\n",
    "            selected_cols = [\n",
    "                '4. close'\n",
    "            ]\n",
    "\n",
    "            df_stock_base = pd.DataFrame(value).transpose()[selected_cols] # tranpose the dataframe and sub select selected cols\n",
    "\n",
    "            # Rename columns\n",
    "            df_stock_base.rename(\n",
    "                columns={\n",
    "                    '4. close': f'{symbol}'\n",
    "                    }\n",
    "                ,inplace=True\n",
    "                )\n",
    "            \n",
    "            df_stock_base[f'{symbol}'] = df_stock_base[f'{symbol}'].astype(str).apply(lambda x: float(x))\n",
    "            df_stock_base[f'{symbol}'] = df_stock_base[f'{symbol}'].round(2)\n",
    "\n",
    "    # Earning section\n",
    "    # past earnings from alpha vintage API\n",
    "    # replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "    url = f'https://www.alphavantage.co/query?function=EARNINGS&symbol={symbol}&apikey={alpha_vantage_api_key}'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if key == 'annualEarnings':\n",
    "\n",
    "            selected_cols = [\n",
    "                'fiscalDateEnding'\n",
    "                ,'reportedEPS'\n",
    "            ]\n",
    "\n",
    "            df_stock_annualEPS = pd.DataFrame(value) # tranpose the dataframe and sub select selected cols\n",
    "\n",
    "\n",
    "        if key == 'quarterlyEarnings':\n",
    "\n",
    "            selected_cols = [\n",
    "                'reportedDate'\n",
    "                ,'reportedEPS'\n",
    "            ]\n",
    "\n",
    "            df_stock_qtrEPS = pd.DataFrame(value)[selected_cols] # tranpose the dataframe and sub select selected cols\n",
    "\n",
    "            # Convert the column to decimal type\n",
    "            for col in selected_cols:\n",
    "                if col in ['reportedEPS']:\n",
    "                    df_stock_qtrEPS[f'{col}'] = df_stock_qtrEPS[f'{col}'].astype(str).apply(lambda x: float(x))\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # # forecast 1 qtr earnings from alpha vantage API\n",
    "    # for i in earning_calendar: comment out the for loop in case of future usage, i can be the parameter of {}month\n",
    "    CSV_URL = f'https://www.alphavantage.co/query?function=EARNINGS_CALENDAR&symbol={symbol}&horizon=12month&apikey={alpha_vantage_api_key}'\n",
    "    with requests.Session() as s:\n",
    "        download = s.get(CSV_URL)\n",
    "        decoded_content = download.content.decode('utf-8')\n",
    "        cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "        my_list = list(cr)\n",
    "\n",
    "        forecast_earanings_df = pd.DataFrame(\n",
    "            columns=my_list[0]\n",
    "            ,data=my_list[1::]\n",
    "            )\n",
    "        \n",
    "        latest_projected_EPS = float(forecast_earanings_df['estimate'].head(1).values)\n",
    "\n",
    "\n",
    "    # forecast 1 year earnings from nasdaq webscrapping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Consolidated section\n",
    "    df_stock_consolidate = df_stock_base.head(window_days)\n",
    "\n",
    "\n",
    "    df_stock_consolidate_date = df_stock_consolidate.index\n",
    "    for i in df_stock_consolidate_date:\n",
    "                \n",
    "        # Filter the DataFrame to include only dates(index) less than or equal to the target date\n",
    "        filtered_df_stock_qtrEPS = df_stock_qtrEPS[df_stock_qtrEPS['reportedDate']<= i]\n",
    "\n",
    "        # Select the first four rows from the past_qtrs_EPS\n",
    "        past_4_qtrs_EPS = filtered_df_stock_qtrEPS.head(4) \n",
    "        past_3_qtrs_EPS = filtered_df_stock_qtrEPS.head(3)\n",
    "\n",
    "        # Calculate the sum of the numeric values in the selected rows\n",
    "        EPS_TTM = past_4_qtrs_EPS['reportedEPS'].values.sum()\n",
    "\n",
    "        # assign each index row with the EPS_TTM\n",
    "        df_stock_consolidate.loc[i, f\"{symbol}_EPS_TTM\"] = EPS_TTM\n",
    "\n",
    "        if i == max(df_stock_consolidate.index):\n",
    "            EPS_latest_projected = latest_projected_EPS + past_3_qtrs_EPS['reportedEPS'].values.sum()  # This metrics is the past 3 qtrs post EPS + 1 projected EPS\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        df_stock_consolidate[f\"{symbol}_EPS_latest_projected\"] = EPS_latest_projected\n",
    "    \n",
    "    # stock's stats\n",
    "    df_stock_consolidate[f\"{symbol}_PE_TTM\"] = (df_stock_consolidate[symbol] / df_stock_consolidate[f\"{symbol}_EPS_TTM\"]).round(2)\n",
    "    df_stock_consolidate[f\"{symbol}_PE_TTM_avg\"] = df_stock_consolidate[f\"{symbol}_PE_TTM\"].mean().round(2)\n",
    "    df_stock_consolidate[f\"{symbol}_PE_TTM_std\"] = np.std(df_stock_consolidate[f\"{symbol}_PE_TTM\"]).round(2)\n",
    "    df_stock_consolidate[f\"{symbol}_PE_TTM_volatility_+\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM_avg\"] + df_stock_consolidate[f\"{symbol}_PE_TTM_std\"]).round(2) # 这个是PE的波动范围上限\n",
    "    df_stock_consolidate[f\"{symbol}_PE_TTM_volatility_-\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM_avg\"] - df_stock_consolidate[f\"{symbol}_PE_TTM_std\"]).round(2) # 这个是PE的波动范围下限\n",
    "\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_+\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM_volatility_+\"] * df_stock_consolidate[f\"{symbol}_EPS_TTM\"]).round(2) # 这个是relative valuation的价格上限\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_-\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM_volatility_-\"] * df_stock_consolidate[f\"{symbol}_EPS_TTM\"]).round(2) # 这个是relative valuation的价格下限\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_median\"] = (np.median([df_stock_consolidate[f\"{symbol}_relative_valuation_+\"], df_stock_consolidate[f\"{symbol}_relative_valuation_-\"]])).round(2) #这个是根据最新TTM PE估值的价格中位数\n",
    "\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_projected_+\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM_volatility_+\"] * df_stock_consolidate[f\"{symbol}_EPS_latest_projected\"]).round(2) # 这个是relative valuation的价格上限\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_projected_-\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM_volatility_-\"] * df_stock_consolidate[f\"{symbol}_EPS_latest_projected\"]).round(2) # 这个是relative valuation的价格下限\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_projected_median\"] = (np.median([df_stock_consolidate[f\"{symbol}_relative_valuation_projected_+\"], df_stock_consolidate[f\"{symbol}_relative_valuation_projected_-\"]])).round(2) #这个是根据3 qtrs post EPS + 1 projected EPS 得出PE估值的价格中位数\n",
    "\n",
    "    df_stock_consolidate[f\"{symbol}_{window_days}_price_min\"] = df_stock_consolidate[symbol].min().round(2)\n",
    "    df_stock_consolidate[f\"{symbol}_{window_days}_price_max\"] = df_stock_consolidate[symbol].max().round(2)\n",
    "    df_stock_consolidate[f\"{symbol}_{window_days}_price_avg\"] = df_stock_consolidate[symbol].mean().round(2)\n",
    "    df_stock_consolidate[f\"{symbol}_{window_days}_price_std\"] = np.std(df_stock_consolidate[symbol]).round(2)\n",
    "\n",
    "\n",
    "\n",
    "    conditions = [\n",
    "    (df_stock_consolidate[f\"{symbol}\"] < df_stock_consolidate[f\"{symbol}_relative_valuation_-\"]),\n",
    "    (df_stock_consolidate[f\"{symbol}\"] > df_stock_consolidate[f\"{symbol}_relative_valuation_+\"]),\n",
    "    ((df_stock_consolidate[f\"{symbol}\"] >= df_stock_consolidate[f\"{symbol}_relative_valuation_-\"]) & (df_stock_consolidate[f\"{symbol}\"] <= df_stock_consolidate[f\"{symbol}_relative_valuation_+\"])),\n",
    "    ]\n",
    "\n",
    "    categories = [\n",
    "        'undervalued'\n",
    "        ,'overvalued'\n",
    "        ,'fair'\n",
    "        ]\n",
    "\n",
    "    # This KPI assess if the current stock price is under/over/fair to the current relative valuation\n",
    "    df_stock_consolidate[f\"{symbol}_curr_assessment\"] = None\n",
    "\n",
    "    for condition, category in zip(conditions, categories):\n",
    "        df_stock_consolidate.loc[condition, f\"{symbol}_price_valuation_assessment\"] = category\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Append key-value pairs to the dictionary\n",
    "    selected_cols = [\n",
    "    f\"{symbol}\"\n",
    "    # ,f\"{symbol}_EPS_TTM\"\n",
    "    # ,f\"{symbol}_EPS_latest_projected\"\n",
    "    ,f\"{symbol}_PE_TTM\"\n",
    "    ,f\"{symbol}_PE_TTM_avg\"\n",
    "    ,f\"{symbol}_relative_valuation_+\"\n",
    "    ,f\"{symbol}_relative_valuation_-\"\n",
    "    ,f\"{symbol}_relative_valuation_median\"\n",
    "    ,f\"{symbol}_relative_valuation_projected_+\"\n",
    "    ,f\"{symbol}_relative_valuation_projected_-\"\n",
    "    ,f\"{symbol}_relative_valuation_projected_median\"\n",
    "    ,f\"{symbol}_price_valuation_assessment\"\n",
    "    ]\n",
    "\n",
    "    ticker_dict[f'{symbol}'] = df_stock_consolidate[selected_cols]\n",
    "\n",
    "    # Addtional setting session\n",
    "    # Set display options to show all rows and columns\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import yfinance as yf\n",
    "# import nasdaqdatalink\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pytz  # Make sure to import pytz for timezone handling\n",
    "import seaborn as sns\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "import json\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"alpha_vantage_api_key\")\n",
    "NASDAQ_DATA_LINK_API_KEY = os.getenv(\"NASDAQ_DATA_LINK_API_KEY\")\n",
    "\n",
    "# nasdaqdatalink.read_key(filename=NASDAQ_DATA_LINK_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addtional setting session\n",
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters section\n",
    "\n",
    "alpha_vantage_api_key = API_KEY # FREE TIER API rate limit is 25 requests per day\n",
    "alpha_vantage_function = {\n",
    "    'core':[\n",
    "        'TIME_SERIES_INTRADA'\n",
    "        ,'TIME_SERIES_DAILY' # this is daily time series quote\n",
    "        ,'TIME_SERIES_DAILY_ADJUSTED' # this is daily time series adjusted by split/dividend-adjusted\n",
    "        ,'GLOBAL_QUOTE'\n",
    "    ]\n",
    "    ,'fundmental':[\n",
    "    'INCOME_STATEMENT'\n",
    "    ,'BALANCE_SHEET' # this is daily time series quote\n",
    "    ,'CASH_FLOW' # this is daily time series adjusted by split/dividend-adjusted\n",
    "    ,'EARNINGS'\n",
    "    ,'EARNINGS_CALENDAR'\n",
    "]\n",
    "}\n",
    "\n",
    "# Define the ticker symbols as a list; eg. TSM,MSFT,AMZN\n",
    "# ticker_symbols = input(\"Enter stock tickers separated by commas:\") \n",
    "# ticker_symbols = ticker_symbols.split(',')\n",
    "ticker_symbols = [\n",
    "    'TSM'\n",
    "]\n",
    "\n",
    "# Time intelligent parameters\n",
    "window_days = 90\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=window_days)\n",
    "earning_calendar = [\n",
    "    3  # this will return next 1 qtr forecast earning; nowadays the earning calendar only shows the next 1 qtr forecast earning\n",
    "    ,6  # this will return next 2 qtr forecast earning\n",
    "    ,12  # this will return next 4 qtr forecast earning\n",
    "]\n",
    "\n",
    "PE_yr_range = 6 # this will return x-1 yr PE range\n",
    "\n",
    "ticker_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PE TTM Valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "DateParseError",
     "evalue": "Unknown datetime string format, unable to parse: NVDA, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 45\u001b[0m\n\u001b[0;32m     41\u001b[0m         Monthly_stock_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(value)\n\u001b[0;32m     44\u001b[0m Monthly_stock_df \u001b[38;5;241m=\u001b[39m Monthly_stock_df\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[1;32m---> 45\u001b[0m Monthly_stock_df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMonthly_stock_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m filter_1 \u001b[38;5;241m=\u001b[39m (Monthly_stock_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39myear\u001b[38;5;241m.\u001b[39misin(\u001b[38;5;28mrange\u001b[39m((datetime\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m-\u001b[39m PE_yr_range) ,datetime\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39myear)))\n\u001b[0;32m     49\u001b[0m filter_2 \u001b[38;5;241m=\u001b[39m (Monthly_stock_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmonth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m12\u001b[39m) \u001b[38;5;66;03m# month = 12 to get the year end closing price\u001b[39;00m\n",
      "File \u001b[1;32me:\\Python\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1076\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1074\u001b[0m         result \u001b[38;5;241m=\u001b[39m _convert_and_box_cache(arg, cache_array, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1075\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1076\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(arg):\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1079\u001b[0m         \u001b[38;5;66;03m# error: Argument 1 to \"_maybe_cache\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# \"Union[float, str, datetime, List[Any], Tuple[Any, ...], ExtensionArray,\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m         \u001b[38;5;66;03m# ndarray[Any, Any], Series]\"; expected \"Union[List[Any], Tuple[Any, ...],\u001b[39;00m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;66;03m# Union[Union[ExtensionArray, ndarray[Any, Any]], Index, Series], Series]\"\u001b[39;00m\n",
      "File \u001b[1;32me:\\Python\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[1;32m--> 435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     out_unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32me:\\Python\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2398\u001b[0m, in \u001b[0;36mobjects_to_datetime64\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, allow_object, out_unit)\u001b[0m\n\u001b[0;32m   2395\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[0;32m   2396\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[1;32m-> 2398\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2403\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabbrev_to_npy_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_unit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2405\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2408\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2409\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, tz_parsed\n",
      "File \u001b[1;32mtslib.pyx:414\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:596\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:553\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mconversion.pyx:641\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:336\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:666\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse: NVDA, at position 0"
     ]
    }
   ],
   "source": [
    "# Daily quote section\n",
    "for symbol in ticker_symbols:\n",
    "\n",
    "\n",
    "    # Daily quote section\n",
    "    # replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={alpha_vantage_api_key}'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if key == 'Time Series (Daily)':\n",
    "\n",
    "            \n",
    "\n",
    "            selected_cols = [\n",
    "                '4. close'\n",
    "            ]\n",
    "\n",
    "            Daily_stock_df = pd.DataFrame(value).transpose()[selected_cols] # tranpose the dataframe and sub select selected cols\n",
    "\n",
    "            # Rename columns\n",
    "            Daily_stock_df.rename(\n",
    "                columns={\n",
    "                    '4. close': f'{symbol}'\n",
    "                    }\n",
    "                ,inplace=True\n",
    "                )\n",
    "            \n",
    "            Daily_stock_df[f'{symbol}'] = Daily_stock_df[f'{symbol}'].astype(str).apply(lambda x: float(x))\n",
    "            Daily_stock_df[f'{symbol}'] = Daily_stock_df[f'{symbol}'].round(2)\n",
    "\n",
    "\n",
    "    # Monthly quote section\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_MONTHLY&symbol={symbol}&apikey={alpha_vantage_api_key}'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if key == 'Monthly Time Series':\n",
    "            Monthly_stock_df = pd.DataFrame(value)\n",
    "\n",
    "\n",
    "    Monthly_stock_df = Monthly_stock_df.transpose()\n",
    "    Monthly_stock_df.index = pd.to_datetime(Monthly_stock_df.index)\n",
    "\n",
    "\n",
    "    filter_1 = (Monthly_stock_df.index.year.isin(range((datetime.today().year - PE_yr_range) ,datetime.today().year)))\n",
    "    filter_2 = (Monthly_stock_df.index.month == 12) # month = 12 to get the year end closing price\n",
    "\n",
    "    selected_cols = [\n",
    "        '4. close'\n",
    "    ]\n",
    "\n",
    "    Monthly_stock_df = Monthly_stock_df[\n",
    "        filter_1\n",
    "        & filter_2\n",
    "    ][selected_cols]\n",
    "\n",
    "    # Rename columns\n",
    "    Monthly_stock_df.rename(\n",
    "        columns={\n",
    "            '4. close': f'{symbol}'\n",
    "            }\n",
    "        ,inplace=True\n",
    "        )\n",
    "\n",
    "    Monthly_stock_df[f'{symbol}'] = Monthly_stock_df[f'{symbol}'].astype(str).apply(lambda x: float(x))\n",
    "    Monthly_stock_df[f'{symbol}'] = Monthly_stock_df[f'{symbol}'].round(2)\n",
    "\n",
    "\n",
    "\n",
    "    # Earning section\n",
    "    # past earnings from alpha vintage API\n",
    "    url = f'https://www.alphavantage.co/query?function=EARNINGS&symbol={symbol}&apikey={alpha_vantage_api_key}'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if key == 'annualEarnings':\n",
    "\n",
    "            selected_cols = [\n",
    "                'fiscalDateEnding'\n",
    "                ,'reportedEPS'\n",
    "            ]\n",
    "\n",
    "            annualEPS_df = pd.DataFrame(value) # tranpose the dataframe and sub select selected cols\n",
    "\n",
    "\n",
    "            annualEPS_df['fiscalDateEnding'] = pd.to_datetime(annualEPS_df['fiscalDateEnding']).dt.year\n",
    "\n",
    "            annualEPS_df = annualEPS_df[\n",
    "                annualEPS_df['fiscalDateEnding'].isin(\n",
    "                    range(\n",
    "                        (datetime.today().year - 6) \n",
    "                        ,datetime.today().year\n",
    "                            )\n",
    "                            )\n",
    "                            ]\n",
    "\n",
    "            # Convert the column to decimal type\n",
    "            for col in selected_cols:\n",
    "                if col in ['reportedEPS']:\n",
    "                    annualEPS_df[f'{col}'] = annualEPS_df[f'{col}'].astype(str).apply(lambda x: float(x))\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            annualEPS_df[f'{symbol}_PE'] = Monthly_stock_df[f'{symbol}'].values / annualEPS_df['reportedEPS'].values\n",
    "            annualEPS_df[f\"{symbol}_PE_{PE_yr_range-1}yr_avg\"] = annualEPS_df[f\"{symbol}_PE\"].mean().round(2)\n",
    "            annualEPS_df[f\"{symbol}_PE_{PE_yr_range-1}yr_std\"] = np.std(annualEPS_df[f\"{symbol}_PE\"]).round(2)\n",
    "            annualEPS_df[f\"{symbol}_PE_{PE_yr_range-1}yr_volatility_+\"] = (annualEPS_df[f\"{symbol}_PE_{PE_yr_range-1}yr_avg\"] + annualEPS_df[f\"{symbol}_PE_{PE_yr_range-1}yr_std\"]).round(2) # 这个是PE的波动范围上限\n",
    "            annualEPS_df[f\"{symbol}_PE_{PE_yr_range-1}yr_volatility_-\"] = (annualEPS_df[f\"{symbol}_PE_{PE_yr_range-1}yr_avg\"] - annualEPS_df[f\"{symbol}_PE_{PE_yr_range-1}yr_std\"]).round(2) # 这个是PE的波动范围下限\n",
    "\n",
    "\n",
    "\n",
    "        if key == 'quarterlyEarnings':\n",
    "\n",
    "            selected_cols = [\n",
    "                'reportedDate'\n",
    "                ,'reportedEPS'\n",
    "            ]\n",
    "\n",
    "            qtrEPS_df = pd.DataFrame(value)[selected_cols] # tranpose the dataframe and sub select selected cols\n",
    "\n",
    "            # Convert the column to decimal type\n",
    "            for col in selected_cols:\n",
    "                if col in ['reportedEPS']:\n",
    "                    qtrEPS_df[f'{col}'] = qtrEPS_df[f'{col}'].astype(str).apply(lambda x: float(x))\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "    # # forecast 1 qtr earnings from alpha vantage API\n",
    "    # for i in earning_calendar: comment out the for loop in case of future usage, i can be the parameter of {}month\n",
    "    CSV_URL = f'https://www.alphavantage.co/query?function=EARNINGS_CALENDAR&symbol={symbol}&horizon=12month&apikey={alpha_vantage_api_key}'\n",
    "    with requests.Session() as s:\n",
    "        download = s.get(CSV_URL)\n",
    "        decoded_content = download.content.decode('utf-8')\n",
    "        cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "        my_list = list(cr)\n",
    "\n",
    "        forecast_earanings_df = pd.DataFrame(\n",
    "            columns=my_list[0]\n",
    "            ,data=my_list[1::]\n",
    "            )\n",
    "        \n",
    "        if forecast_earanings_df['estimate'].head(1).values != '':\n",
    "            latest_projected_EPS = float(forecast_earanings_df['estimate'].head(1).values)\n",
    "        else:\n",
    "            latest_projected_EPS = 0\n",
    "\n",
    "\n",
    "    # forecast 1 year earnings from yf API\n",
    "    yf_data = yf.Ticker(symbol)\n",
    "        \n",
    "\n",
    "    EPS_12month_projected = yf_data.info['forwardEps'] # 代表了截止下一个日历年结束的EPS, next year forecasted EPS\n",
    "    PE_12month_projected = yf_data.info['forwardPE'] # 代表了截止下一个日历年结束的PE, next year forecasted PE\n",
    "    PEG_12month_projected = yf_data.info['pegRatio'] # 代表了截止下一个日历年结束的PEG \n",
    "\n",
    "\n",
    "    # Consolidated section\n",
    "    df_stock_consolidate = Daily_stock_df.head(window_days)\n",
    "\n",
    "\n",
    "    df_stock_consolidate_date = df_stock_consolidate.index\n",
    "    for i in df_stock_consolidate_date:\n",
    "                \n",
    "        # Filter the DataFrame to include only dates(index) less than or equal to the target date\n",
    "        filtered_qtrEPS_df = qtrEPS_df[qtrEPS_df['reportedDate']<= i]\n",
    "\n",
    "        # Select the first four rows from the past_qtrs_EPS\n",
    "        past_4_qtrs_EPS = filtered_qtrEPS_df.head(4) \n",
    "        past_3_qtrs_EPS = filtered_qtrEPS_df.head(3)\n",
    "\n",
    "        # Calculate the sum of the numeric values in the selected rows\n",
    "        EPS_TTM = past_4_qtrs_EPS['reportedEPS'].values.sum()\n",
    "\n",
    "        # assign each index row with the EPS_TTM\n",
    "        df_stock_consolidate.loc[i, f\"{symbol}_EPS_TTM\"] = EPS_TTM\n",
    "\n",
    "        if i == max(df_stock_consolidate.index):\n",
    "            EPS_latest_projected = latest_projected_EPS + past_3_qtrs_EPS['reportedEPS'].values.sum()  # This metrics is the past 3 qtrs post EPS + 1 projected EPS\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        df_stock_consolidate[f\"{symbol}_EPS_latest_projected\"] = EPS_latest_projected\n",
    "    \n",
    "    # stock's stats\n",
    "    df_stock_consolidate[f\"{symbol}_PE_TTM\"] = (df_stock_consolidate[symbol] / df_stock_consolidate[f\"{symbol}_EPS_TTM\"]).round(2)\n",
    "    df_stock_consolidate[f\"{symbol}_PE_TTM_avg\"] = df_stock_consolidate[f\"{symbol}_PE_TTM\"].mean().round(2)\n",
    "    df_stock_consolidate[f\"{symbol}_PE_TTM_std\"] = np.std(df_stock_consolidate[f\"{symbol}_PE_TTM\"]).round(2)\n",
    "    df_stock_consolidate[f\"{symbol}_PE_TTM_volatility_+\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM_avg\"] + df_stock_consolidate[f\"{symbol}_PE_TTM_std\"]).round(2) # 这个是PE的波动范围上限\n",
    "    df_stock_consolidate[f\"{symbol}_PE_TTM_volatility_-\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM_avg\"] - df_stock_consolidate[f\"{symbol}_PE_TTM_std\"]).round(2) # 这个是PE的波动范围下限\n",
    "\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_TTM_+\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM_volatility_+\"] * df_stock_consolidate[f\"{symbol}_EPS_TTM\"]).round(2) # 这个是relative valuation的价格上限\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_TTM_-\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM_volatility_-\"] * df_stock_consolidate[f\"{symbol}_EPS_TTM\"]).round(2) # 这个是relative valuation的价格下限\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_TTM_median\"] = (np.median([df_stock_consolidate[f\"{symbol}_relative_valuation_TTM_+\"], df_stock_consolidate[f\"{symbol}_relative_valuation_TTM_-\"]])).round(2) #这个是根据最新TTM PE估值的价格中位数\n",
    "\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_nextQuater_projected_+\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM_volatility_+\"] * df_stock_consolidate[f\"{symbol}_EPS_latest_projected\"]).round(2) # 这个是relative valuation的价格上限\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_nextQuater_projected_-\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM_volatility_-\"] * df_stock_consolidate[f\"{symbol}_EPS_latest_projected\"]).round(2) # 这个是relative valuation的价格下限\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_nextQuater_projected_median\"] = (np.median([df_stock_consolidate[f\"{symbol}_relative_valuation_nextQuater_projected_+\"], df_stock_consolidate[f\"{symbol}_relative_valuation_nextQuater_projected_-\"]])).round(2) #这个是根据3 qtrs post EPS + 1 projected EPS 得出PE估值的价格中位数\n",
    "\n",
    "    df_stock_consolidate[f\"{symbol}_{window_days}_price_min\"] = df_stock_consolidate[symbol].min().round(2)\n",
    "    df_stock_consolidate[f\"{symbol}_{window_days}_price_max\"] = df_stock_consolidate[symbol].max().round(2)\n",
    "    df_stock_consolidate[f\"{symbol}_{window_days}_price_avg\"] = df_stock_consolidate[symbol].mean().round(2)\n",
    "    df_stock_consolidate[f\"{symbol}_{window_days}_price_std\"] = np.std(df_stock_consolidate[symbol]).round(2)\n",
    "\n",
    "    df_stock_consolidate[f\"{symbol}_PE_{PE_yr_range-1}yr_avg\"] = annualEPS_df[f\"{symbol}_PE_{PE_yr_range-1}yr_avg\"].values[0]\n",
    "    df_stock_consolidate[f\"{symbol}_PE_{PE_yr_range-1}yr_std\"] = annualEPS_df[f\"{symbol}_PE_{PE_yr_range-1}yr_std\"].values[0]\n",
    "    df_stock_consolidate[f\"{symbol}_PE_{PE_yr_range-1}yr_volatility_+\"] = annualEPS_df[f\"{symbol}_PE_{PE_yr_range-1}yr_volatility_+\"].values[0]\n",
    "    df_stock_consolidate[f\"{symbol}_PE_{PE_yr_range-1}yr_volatility_-\"] = annualEPS_df[f\"{symbol}_PE_{PE_yr_range-1}yr_volatility_-\"].values[0]\n",
    "\n",
    "\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_nextYear_projected_+\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM_volatility_+\"] * EPS_12month_projected).round(2) # 这个是relative valuation的价格上限\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_nextYear_projected_-\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM_volatility_-\"] * EPS_12month_projected).round(2) # 这个是relative valuation的价格下限\n",
    "    df_stock_consolidate[f\"{symbol}_relative_valuation_nextYear_projected_median\"] = (np.median([df_stock_consolidate[f\"{symbol}_relative_valuation_nextYear_projected_+\"], df_stock_consolidate[f\"{symbol}_relative_valuation_nextYear_projected_-\"]])).round(2) #这个是根据next year projected EPS 得出PE估值的价格中位数\n",
    "\n",
    "    df_stock_consolidate[f\"{symbol}_next12months_PEG\"] = PEG_12month_projected\n",
    "    df_stock_consolidate[f\"{symbol}_TTM_PEG\"] = (df_stock_consolidate[f\"{symbol}_PE_TTM\"] / (((EPS_12month_projected - df_stock_consolidate[f\"{symbol}_EPS_TTM\"]) / df_stock_consolidate[f\"{symbol}_EPS_TTM\"]) * 100)).round(2) # 这个是截止下一年的EPS growth rate所得出的PEG ratio, <1是undervalue的表现\n",
    "    \n",
    "    df_stock_consolidate[f\"{symbol}_nextYear_EPS_growthRate\"] = (((EPS_12month_projected - df_stock_consolidate[f\"{symbol}_EPS_TTM\"]) / df_stock_consolidate[f\"{symbol}_EPS_TTM\"]) * 100).round(2)\n",
    "    df_stock_consolidate[f\"{symbol}_nextQuater_EPS_growthRate\"] = (((df_stock_consolidate[f\"{symbol}_EPS_latest_projected\"] - df_stock_consolidate[f\"{symbol}_EPS_TTM\"]) / df_stock_consolidate[f\"{symbol}_EPS_TTM\"]) * 100).round(2)\n",
    "\n",
    "\n",
    "\n",
    "    conditions = [\n",
    "    (df_stock_consolidate[f\"{symbol}\"] < df_stock_consolidate[f\"{symbol}_relative_valuation_TTM_-\"]),\n",
    "    (df_stock_consolidate[f\"{symbol}\"] > df_stock_consolidate[f\"{symbol}_relative_valuation_TTM_+\"]),\n",
    "    ((df_stock_consolidate[f\"{symbol}\"] >= df_stock_consolidate[f\"{symbol}_relative_valuation_TTM_-\"]) & (df_stock_consolidate[f\"{symbol}\"] <= df_stock_consolidate[f\"{symbol}_relative_valuation_TTM_+\"])),\n",
    "    ]\n",
    "\n",
    "    categories = [\n",
    "        'undervalued'\n",
    "        ,'overvalued'\n",
    "        ,'fair'\n",
    "        ]\n",
    "\n",
    "    # This KPI assess if the current stock price is under/over/fair to the current relative valuation\n",
    "    df_stock_consolidate[f\"{symbol}_curr_assessment\"] = None\n",
    "\n",
    "    for condition, category in zip(conditions, categories):\n",
    "        df_stock_consolidate.loc[condition, f\"{symbol}_price_valuation_assessment\"] = category\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Append key-value pairs to the dictionary\n",
    "    selected_cols = [\n",
    "    f\"{symbol}\"\n",
    "    ,f\"{symbol}_EPS_TTM\"\n",
    "    ,f\"{symbol}_EPS_latest_projected\"\n",
    "    ,f\"{symbol}_PE_TTM\"\n",
    "    ,f\"{symbol}_PE_TTM_avg\"\n",
    "    # ,f\"{symbol}_PE_{PE_yr_range-1}yr_avg\"\n",
    "    # ,f\"{symbol}_PE_{PE_yr_range-1}yr_volatility_+\"\n",
    "    # ,f\"{symbol}_PE_{PE_yr_range-1}yr_volatility_-\"\n",
    "    ,f\"{symbol}_relative_valuation_TTM_+\"\n",
    "    ,f\"{symbol}_relative_valuation_TTM_-\"\n",
    "    ,f\"{symbol}_relative_valuation_TTM_median\"\n",
    "    ,f\"{symbol}_relative_valuation_nextQuater_projected_+\"\n",
    "    ,f\"{symbol}_relative_valuation_nextQuater_projected_-\"\n",
    "    ,f\"{symbol}_relative_valuation_nextQuater_projected_median\"\n",
    "    ,f\"{symbol}_relative_valuation_nextYear_projected_+\"\n",
    "    ,f\"{symbol}_relative_valuation_nextYear_projected_-\"\n",
    "    ,f\"{symbol}_relative_valuation_nextYear_projected_median\"\n",
    "    ,f\"{symbol}_price_valuation_assessment\"\n",
    "    ,f\"{symbol}_nextQuater_EPS_growthRate\"\n",
    "    ,f\"{symbol}_nextYear_EPS_growthRate\"\n",
    "    ,f\"{symbol}_next12months_PEG\"\n",
    "    ,f\"{symbol}_TTM_PEG\"\n",
    "    ]\n",
    "\n",
    "    ticker_dict[f'{symbol}'] = df_stock_consolidate[selected_cols]\n",
    "\n",
    "    # Addtional setting session\n",
    "    # Set display options to show all rows and columns\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TSM'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mticker_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTSM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'TSM'"
     ]
    }
   ],
   "source": [
    "ticker_dict['TSM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "CSV_URL = 'https://www.alphavantage.co/query?function=IPO_CALENDAR&apikey={alpha_vantage_api_key}'\n",
    "\n",
    "with requests.Session() as s:\n",
    "    download = s.get(CSV_URL)\n",
    "    decoded_content = download.content.decode('utf-8')\n",
    "    cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "    my_list = list(cr)\n",
    "\n",
    "    IPO_df = pd.DataFrame(columns=my_list[0]\n",
    "                          ,data=my_list[1::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>ipoDate</th>\n",
       "      <th>priceRangeLow</th>\n",
       "      <th>priceRangeHigh</th>\n",
       "      <th>currency</th>\n",
       "      <th>exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FSHPU</td>\n",
       "      <td>Flag Ship Acquisition Corp. Unit</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NASDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCIXW</td>\n",
       "      <td>Churchill Capital Corp IX Warrant</td>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NASDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCIX</td>\n",
       "      <td>Churchill Capital Corp IX Ordinary Shares</td>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NASDAQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                                       name     ipoDate priceRangeLow  \\\n",
       "0  FSHPU           Flag Ship Acquisition Corp. Unit  2024-06-18             0   \n",
       "1  CCIXW          Churchill Capital Corp IX Warrant  2024-06-21             0   \n",
       "2   CCIX  Churchill Capital Corp IX Ordinary Shares  2024-06-21             0   \n",
       "\n",
       "  priceRangeHigh currency exchange  \n",
       "0              0      USD   NASDAQ  \n",
       "1              0      USD   NASDAQ  \n",
       "2              0      USD   NASDAQ  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPO_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
